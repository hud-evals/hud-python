---
title: "hud eval"
description: "Run agents on tasks or datasets"
icon: "robot"
---

The `hud eval` command runs an agent on a tasks file or platform taskset.

<Note>
**Local Execution Dependencies**: Running Claude or Gemini agents locally requires additional packages:
```bash
uv add "hud-python[agents]"
```
This is not needed for `--remote` execution, which runs on HUD infrastructure.
</Note>

## Usage

```bash
hud eval [SOURCE] [AGENT] [OPTIONS]
```

## Arguments

<ParamField path="source" type="string">
  Platform taskset name (e.g., `My Tasks`) or local task JSON/JSONL file. When loading from a platform taskset, the job is automatically associated with that taskset.
</ParamField>

<ParamField path="agent" type="string">
  Agent to use: `claude`, `openai`, `operator`, `gemini`, `gemini_cua`, `openai_compatible`. If omitted, an interactive preset selector appears.
</ParamField>

## Options

### Execution Mode

<ParamField path="--full" type="boolean" default="false">
  Run the entire dataset. Without this flag, only the first task runs (debug mode).
</ParamField>

<ParamField path="--remote" type="boolean" default="false">
  Submit tasks to HUD platform for remote execution. Fire-and-forget - monitor at hud.ai.
</ParamField>

<ParamField path="--task-ids" type="string">
  Comma-separated task IDs to run (e.g., `task_1,task_5`). Overrides `--full`.
</ParamField>

<ParamField path="--group-size" type="integer" default="1">
  Number of times to run each task (for variance estimation).
</ParamField>

### Agent Configuration

<ParamField path="--model, -m" type="string">
  Model/checkpoint name (e.g., `claude-sonnet-4-5`, `gpt-5`).
</ParamField>

<ParamField path="--config, -c" type="string" repeatable>
  Agent config overrides as `key=value`. Supports namespaced keys like `claude.max_tokens=32768`.
</ParamField>

<ParamField path="--allowed-tools" type="string">
  Comma-separated tools to expose to the agent.
</ParamField>

<ParamField path="--disallowed-tools" type="string">
  Comma-separated tools to hide from the agent.
</ParamField>

### Execution Limits

<ParamField path="--max-concurrent" type="integer" default="30">
  Maximum concurrent tasks (local execution only).
</ParamField>

<ParamField path="--max-steps" type="integer">
  Maximum steps per task. Default: 10 (single task) or 100 (`--full`).
</ParamField>

<ParamField path="--auto-respond" type="boolean">
  Use ResponseAgent to decide when to stop/continue. Default: True for `--full`.
</ParamField>

### Taskset Association

<ParamField path="--taskset" type="string">
  Taskset name to associate the job with. Resolves the name to a taskset UUID on the platform. Useful when running from a local file but wanting the job to appear under a platform taskset.
</ParamField>

### LLM Routing

<ParamField path="--gateway" type="boolean" default="false">
  Route LLM API calls through HUD Gateway. If you have API keys stored on the platform, they're used automatically (BYOK) at a lower credit cost. Otherwise, pooled keys are used.
</ParamField>

### Output & Confirmation

<ParamField path="--verbose, -v" type="boolean" default="false">
  Enable verbose agent output.
</ParamField>

<ParamField path="--very-verbose, -vv" type="boolean" default="false">
  Enable debug-level logs.
</ParamField>

<ParamField path="--quiet" type="boolean" default="false">
  Suppress opening the browser for eval links.
</ParamField>

<ParamField path="--yes, -y" type="boolean" default="false">
  Skip confirmation prompt.
</ParamField>

## Configuration File

`hud eval` supports a `.hud_eval.toml` config file. Settings are merged with CLI args taking precedence:

**CLI arguments > .hud_eval.toml > defaults**

On first run, a template is created:

```toml
# .hud_eval.toml
[eval]
# source = "My Tasks"
# agent = "claude"
# full = false
# max_concurrent = 30
# max_steps = 10
# group_size = 1
# task_ids = ["checkout-smoke", "0"]  # slugs or 0-based indices
# auto_respond = true
# gateway = false
# quiet = false

[agent]
# allowed_tools = ["computer", "playwright"]
# disallowed_tools = []

[claude]
# model = "claude-sonnet-4-5"
# max_tokens = 16384

[openai]
# model = "gpt-4o"
# temperature = 0.7
# max_output_tokens = 4096

[gemini]
# model = "gemini-2.5-pro"
# temperature = 1.0

[openai_compatible]
# model = "my-model"
# base_url = "http://localhost:8000/v1"
```

## Examples

```bash
# Run a platform taskset (single task)
hud eval "My Tasks" claude

# Full taskset evaluation
hud eval "My Tasks" claude --full

# Run from a local file
hud eval tasks.json claude --full

# Local file, associated with a platform taskset
hud eval tasks.json claude --full --taskset "My Tasks"

# Run specific tasks by ID
hud eval tasks.json claude --task-ids task_1,task_5

# With model override
hud eval tasks.json openai --model gpt-4o

# Agent config overrides
hud eval tasks.json claude --config max_tokens=32768
hud eval tasks.json openai --config temperature=0.7

# High concurrency
hud eval "My Tasks" claude --full --max-concurrent 100

# Variance estimation (run each task 3 times)
hud eval "My Tasks" claude --full --group-size 3

# Remote execution on HUD platform
hud eval "My Tasks" claude --full --remote

# Route through HUD Gateway (no provider API keys needed)
hud eval tasks.json claude --full --gateway

# OpenAI-compatible endpoint (vLLM, Ollama, etc.)
hud eval tasks.json openai_compatible \
    --config base_url=http://localhost:8000/v1 \
    --model llama3.1

# Skip confirmation
hud eval tasks.json claude --full -y

# Verbose debugging
hud eval tasks.json claude -vv
```

## Interactive Mode

When agent is omitted, an interactive selector shows presets:

```
? Select an agent:
‚ùØ Claude Sonnet 4.5
  GPT-5
  Operator (OpenAI Computer Use)
  Gemini 3 Pro Preview
  Gemini CUA (Gemini Computer Use)
  Grok 4-1 Fast (xAI)
```

## Remote Execution

With `--remote`, both the **agent** and **environment** run on HUD infrastructure:

```bash
hud eval "My Tasks" claude --full --remote
```

- **Remote agent**: Runs on HUD workers (no local compute needed)
- **Remote environment**: Tasks must use URL-based `mcp_config` (not local Docker)
- Uses HUD Gateway - no model-specific API keys needed
- Monitor progress at `https://hud.ai/jobs/{job_id}`
- Cancel with `hud cancel`

<Note>
Tasks with local Docker configs (`command`-based `mcp_config`) cannot be run remotely. Convert them first:
```bash
hud convert tasks.json
```
</Note>

<Note>
Remote execution requires `HUD_API_KEY`. Gemini and Operator agents are not supported remotely.
</Note>

## Cancellation

Cancel remote jobs:

```bash
# Cancel a specific job
hud cancel <job_id>

# Cancel a specific trace within a job
hud cancel <job_id> --trace-id <trace_id>

# Cancel ALL your active jobs
hud cancel --all
```

## See Also

- [Tasks Reference](/reference/tasks) - Task configuration
- [Agents Reference](/reference/agents) - Agent options
- [`hud rft`](/reference/cli/rft) - Reinforcement fine-tuning
- [`hud cancel`](/reference/cli/misc) - Cancel remote jobs
