{
  "base_model": "Qwen/Qwen2.5-VL-3B-Instruct",
  "processor": {
    "min_pixels": 50176,
    "max_pixels": 200704,
    "trust_remote_code": true
  },
  "training_steps": 2,
  "shuffle_dataset": false,
  "batch_size": 64,
  "mini_batch_size": 4,
  "group_size": 8,
  "num_gpus": 2,
  "rewards": {
    "scale_rewards": "group",
    "leave_one_out": false
  },
  "buffer_steps": 4,
  "select_strategy": "recent",
  "training": {
    "model": {
      "attn_implementation": "flash_attention_2",
      "trust_remote_code": true,
      "use_liger": true,
      "freeze_vision_tower": true
    },
    "checkpoint": {
      "out_dir": "./checkpoints",
      "checkpoint_prefix": "cua-grpo-step"
    },
    "dp_replicate": 1,
    "dp_shard": 1,
    "save_every_batches": 1,
    "epochs": 1,
    "update_after_group": true,
    "accumulate_over_minibatches": false,
    "ppo_mode": "per_token",
    "token_agg": "mean",
    "kl_beta": 0.0,
    "entropy_beta": 0.0,
    "top_eps": 0.2,
    "bottom_eps": 0.1,
    "grad_clip": 1.0,
    "optimizer": {
      "lr": 3e-5,
      "use_8bit_optimizer": true,
      "adam_betas": [0.9, 0.999],
      "adam_eps": 1e-8
    }
  },
  "actor": {
    "max_steps_per_episode": 5,
    "max_parallel_episodes": 48,
    "temperature": 0.7,
    "max_new_tokens": 1024,
    "vllm_base_url": "http://localhost:8000/v1",
    "vllm_api_key": "token-abc123",
    "force_tool_choice": false,
    "request_timeout": 45,
    "episode_timeout_sec": 600
  },
  "job_name": "j-test-run",
  "stats_interval": 1,
  "verbose": false,
  "seed": 1234
}